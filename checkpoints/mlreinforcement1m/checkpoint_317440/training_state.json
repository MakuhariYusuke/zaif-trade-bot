{
  "current_step": 317440,
  "rewards_history": [
    1754714.2150947005,
    -37515.32363238186,
    363295.1459833123,
    -3573.0354269645736,
    -14726894.9755074,
    16798390.4692348,
    -18733930.435664415,
    0.0,
    -2769420.255859635,
    3871113.1370932795,
    -4176578.190337375,
    376411.5235884764,
    12055707.833498448,
    -1071064.8349898458,
    -41740374.00982348,
    376924.51007548993,
    -31479895.30262443,
    -18866818.560117595,
    2505505.1416351516,
    -409833.4736665264,
    -19355856.57500763,
    24984691.456609692,
    -11316599.423319617,
    3140270.433729597,
    -1976139.1180732828,
    34638431.84678828,
    -2599233.3705747835,
    -3947691.7993082013,
    21384185.29263483,
    2033240.8030176666,
    17396960.193971578
  ],
  "steps_history": [
    10240,
    20480,
    30720,
    40960,
    51200,
    61440,
    71680,
    81920,
    92160,
    102400,
    112640,
    122880,
    133120,
    143360,
    153600,
    163840,
    174080,
    184320,
    194560,
    204800,
    215040,
    225280,
    235520,
    245760,
    256000,
    266240,
    276480,
    286720,
    296960,
    307200,
    317440
  ],
  "reward_stats": {
    "mean": 0.0,
    "variance": 0.0,
    "std": 0.0,
    "count": 0
  },
  "session_id": "mlreinforcement1m"
}
{
  "current_step": 163840,
  "rewards_history": [
    1754714.2150947005,
    -37515.32363238186,
    363295.1459833123,
    -3573.0354269645736,
    -14726894.9755074,
    16798390.4692348,
    -18733930.435664415,
    0.0,
    -2769420.255859635,
    3871113.1370932795,
    -4176578.190337375,
    376411.5235884764,
    12055707.833498448,
    -1071064.8349898458,
    -41740374.00982348,
    376924.51007548993
  ],
  "steps_history": [
    10240,
    20480,
    30720,
    40960,
    51200,
    61440,
    71680,
    81920,
    92160,
    102400,
    112640,
    122880,
    133120,
    143360,
    153600,
    163840
  ],
  "reward_stats": {
    "mean": 0.0,
    "variance": 0.0,
    "std": 0.0,
    "count": 0
  },
  "session_id": "mlreinforcement1m"
}
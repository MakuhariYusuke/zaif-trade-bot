name: Coverage Merge & Pages

on:
  workflow_dispatch:
  workflow_run:
    workflows: ["Tests (Matrix)"]
    types:
      - completed

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: pages-coverage
  cancel-in-progress: true

jobs:
  build:
    if: ${{ github.event_name == 'workflow_dispatch' || github.event.workflow_run.conclusion != '' }}
    runs-on: ubuntu-latest
    steps:
      - name: Check Pages availability (optional)
        continue-on-error: true
        uses: actions/github-script@v7
        with:
          script: |
            try {
              await github.rest.repos.getPages({ owner: context.repo.owner, repo: context.repo.repo });
              core.info('Pages appears enabled.');
            } catch (e) {
              core.warning(`Pages not enabled or inaccessible: ${e.message}`);
            }
      - name: Checkout
        uses: actions/checkout@v4

      - name: Try download merged coverage
        id: dl_merged
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: coverage-merged
          path: coverage-merged

      - name: Download per-group artifacts (fallback)
        if: ${{ !hashFiles('coverage-merged/coverage-final.json') }}
        uses: actions/download-artifact@v4
        with:
          path: artifacts
          pattern: coverage-*
          merge-multiple: true

      - name: Merge coverage (fallback)
        if: ${{ !hashFiles('coverage-merged/coverage-final.json') }}
        shell: bash
        run: |
          set -e
          echo "Scanning artifacts for coverage-final.json files (fallback)..."
          node << 'EOF'
          const fs = require('fs');
          const path = require('path');
          const base = 'artifacts';
          function listFiles(dir) {
            let out = [];
            if (!fs.existsSync(dir)) return out;
            for (const entry of fs.readdirSync(dir, { withFileTypes: true })) {
              const p = path.join(dir, entry.name);
              if (entry.isDirectory()) out = out.concat(listFiles(p));
              else if (entry.isFile() && entry.name === 'coverage-final.json') out.push(p);
            }
            return out;
          }
          const files = listFiles(base);
          console.log(`Found ${files.length} coverage files`);
          const agg = {};
          let parsed = 0, skipped = 0;
          for (const f of files) {
            const raw = fs.readFileSync(f, 'utf8');
            let text = raw.trim();
            let data;
            try {
              data = JSON.parse(text);
            } catch (e) {
              const start = text.indexOf('{');
              const end = text.lastIndexOf('}');
              if (start !== -1 && end !== -1 && end > start) {
                try { data = JSON.parse(text.slice(start, end + 1)); } catch (e2) {}
              }
            }
            if (!data || typeof data !== 'object') { skipped++; continue; }
            parsed++;
            for (const [file, cov] of Object.entries(data)) {
              if (!agg[file]) { agg[file] = cov; continue; }
              const a = agg[file], b = cov;
              if (a.statementMap && b.statementMap && a.s && b.s) {
                for (const k of Object.keys(b.s)) a.s[k] = (a.s[k]||0) + (b.s[k]||0);
              }
              if (a.fnMap && b.fnMap && a.f && b.f) {
                for (const k of Object.keys(b.f)) a.f[k] = (a.f[k]||0) + (b.f[k]||0);
              }
              if (a.branchMap && b.branchMap && a.b && b.b) {
                for (const k of Object.keys(b.b)) {
                  if (!a.b[k]) a.b[k] = b.b[k];
                  else {
                    const arrA = a.b[k]; const arrB = b.b[k];
                    const n = Math.max(arrA.length, arrB.length);
                    for (let i=0;i<n;i++) a.b[k][i] = (arrA[i]||0) + (arrB[i]||0);
                  }
                }
              }
            }
          }
          fs.mkdirSync('coverage-merged', { recursive: true });
          fs.writeFileSync('coverage-merged/coverage-final.json', JSON.stringify(agg));
          console.log(`Parsed ${parsed}, skipped ${skipped}`);
          // Also create a simple summary for consistency
          let totalSt=0, coveredSt=0, totalLn=0, coveredLn=0;
          for (const cov of Object.values(agg)){
            const sMap = cov.statementMap||{}; const sHits = cov.s||{};
            for (const k of Object.keys(sMap)) { totalSt++; if ((sHits[k]||0)>0) coveredSt++; }
            const bMap = cov.branchMap||{}; const bHits = cov.b||{};
            for (const k of Object.keys(bMap)) {
              const arr = bHits[k]||[]; const len = Array.isArray(arr)?arr.length:0;
              totalLn += len; coveredLn += arr.filter(x=>x>0).length;
            }
          }
          const pctSt = totalSt? (coveredSt/totalSt*100).toFixed(2): '0.00';
          const pctLn = totalLn? (coveredLn/totalLn*100).toFixed(2): '0.00';
          fs.writeFileSync('coverage-merged/summary.json', JSON.stringify({ statements: pctSt, lines: pctLn }));
          EOF

      - name: Prepare public bundle
        shell: bash
        run: |
          set -e
          mkdir -p public/coverage
          if [ -f coverage-merged/coverage-final.json ]; then
            cp -r coverage-merged/coverage-final.json public/coverage/coverage-final.json
          else
            echo '{}' > public/coverage/coverage-final.json
          fi
          # Attach first HTML coverage if exists in artifacts
          if ls artifacts/**/index.html 1> /dev/null 2>&1; then
            mkdir -p public/coverage-html
            FIRST_HTML_DIR=$(dirname $(ls -1 artifacts/**/index.html | head -n1))
            cp -r "$FIRST_HTML_DIR"/* public/coverage-html/
          fi

      - name: Setup Pages
        uses: actions/configure-pages@v5
        continue-on-error: true

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./public

      - name: Upload public bundle (artifact)
        uses: actions/upload-artifact@v4
        with:
          name: coverage-public
          path: ./public

  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
        continue-on-error: true

name: Tests (Matrix)

on:
  workflow_dispatch: {}
  pull_request:
  push:
    branches: [ main ]
  schedule:
    - cron: '0 3 * * *'

permissions:
  contents: read
  actions: read
  issues: write
  pull-requests: write

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        group: [ unit, integration, cb-rate, event-metrics ]
        include:
          - group: unit
            script: npm run test:unit -- --coverage
          - group: integration
            script: npm run test:integration-fast -- --coverage
          - group: cb-rate
            script: npm run test:cb-rate -- --coverage
          - group: event-metrics
            script: npm run test:event-metrics -- --coverage
    env:
      FAST_CI: '1'
      TEST_SLEEP_MS: '5'
      ML_MAX_WORKERS: '1'
      RETRY_ATTEMPTS: '1'
      RETRY_BACKOFF_MS: '10'
      DETECT_LEAKS: '1'
      DETECT_LEAKS_STRICT: '0'
      CI: 'true'
      COVERAGE_STMTS: '0'
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: npm
      - name: Install deps
        run: npm ci
      - name: Build
        run: npm run build
      - name: Run tests (${{ matrix.group }})
        run: ${{ matrix.script }}
      - name: Upload coverage (${{ matrix.group }})
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-${{ matrix.group }}
          path: |
            coverage/**
            vitest-report-*.json

  nightly-long:
    if: github.event_name == 'schedule' || (github.event_name == 'workflow_dispatch' && github.event.inputs.run_long == 'true')
    runs-on: ubuntu-latest
    env:
      LONG_TESTS: '1'
      COVERAGE_STMTS: '0'
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: npm
      - name: Install deps
        run: npm ci
      - name: Build
        run: npm run build
      - name: Run long/heavy tests (with coverage)
        run: npm run test:long -- --coverage
      - name: Upload coverage (long)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-long
          path: |
            coverage/**
            vitest-report-long.json

  summarize:
    needs: [test]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Download coverage artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts
          pattern: coverage-*
          merge-multiple: true
      - name: Install Node + nyc
        uses: actions/setup-node@v4
        with:
          node-version: 20
      - name: Merge coverage (v8 JSON)
        run: |
          set -e
          echo "Scanning artifacts for coverage-final.json files..."
          node << 'EOF'
          const fs = require('fs');
          const path = require('path');
          const base = 'artifacts';
          function listFiles(dir) {
            let out = [];
            for (const entry of fs.readdirSync(dir, { withFileTypes: true })) {
              const p = path.join(dir, entry.name);
              if (entry.isDirectory()) out = out.concat(listFiles(p));
              else if (entry.isFile() && entry.name === 'coverage-final.json') out.push(p);
            }
            return out;
          }
          const files = fs.existsSync(base) ? listFiles(base) : [];
          console.log(`Found ${files.length} coverage files`);
          const agg = {};
          let parsed = 0, skipped = 0;
          for (const f of files) {
            const raw = fs.readFileSync(f, 'utf8');
            let text = raw.trim();
            let data;
            try {
              data = JSON.parse(text);
            } catch (e) {
              const start = text.indexOf('{');
              const end = text.lastIndexOf('}');
              if (start !== -1 && end !== -1 && end > start) {
                try { data = JSON.parse(text.slice(start, end + 1)); } catch (e2) {}
              }
            }
            if (!data || typeof data !== 'object') { skipped++; continue; }
            parsed++;
            for (const [file, cov] of Object.entries(data)) {
              if (!agg[file]) { agg[file] = cov; continue; }
              const a = agg[file], b = cov;
              if (a.statementMap && b.statementMap && a.s && b.s) {
                for (const k of Object.keys(b.s)) a.s[k] = (a.s[k]||0) + (b.s[k]||0);
              }
              if (a.fnMap && b.fnMap && a.f && b.f) {
                for (const k of Object.keys(b.f)) a.f[k] = (a.f[k]||0) + (b.f[k]||0);
              }
              if (a.branchMap && b.branchMap && a.b && b.b) {
                for (const k of Object.keys(b.b)) {
                  if (!a.b[k]) a.b[k] = b.b[k];
                  else {
                    const arrA = a.b[k]; const arrB = b.b[k];
                    const n = Math.max(arrA.length, arrB.length);
                    for (let i=0;i<n;i++) a.b[k][i] = (arrA[i]||0) + (arrB[i]||0);
                  }
                }
              }
            }
          }
          fs.mkdirSync('coverage-merged', { recursive: true });
          fs.writeFileSync('coverage-merged/coverage-final.json', JSON.stringify(agg));
          console.log(`Parsed ${parsed}, skipped ${skipped}`);
          // Derive summary
          let totalSt=0, coveredSt=0, totalLn=0, coveredLn=0;
          for (const cov of Object.values(agg)){
            const sMap = cov.statementMap||{}; const sHits = cov.s||{};
            for (const k of Object.keys(sMap)) { totalSt++; if ((sHits[k]||0)>0) coveredSt++; }
            const bMap = cov.branchMap||{}; const bHits = cov.b||{};
            for (const k of Object.keys(bMap)) {
              const arr = bHits[k]||[]; const len = Array.isArray(arr)?arr.length:0;
              totalLn += len; coveredLn += arr.filter(x=>x>0).length;
            }
          }
          const pctSt = totalSt? (coveredSt/totalSt*100).toFixed(2): '0.00';
          const pctLn = totalLn? (coveredLn/totalLn*100).toFixed(2): '0.00';
          fs.writeFileSync('coverage-merged/summary.json', JSON.stringify({ statements: pctSt, lines: pctLn }));
          console.log(`STATEMENTS=${pctSt}`);
          console.log(`LINES=${pctLn}`);
          EOF
      - name: Upload merged coverage
        uses: actions/upload-artifact@v4
        with:
          name: coverage-merged
          path: coverage-merged/**
      - name: Post merged coverage to summary
        run: |
          if [ -f coverage-merged/summary.json ]; then
            STMT=$(node -p "require('./coverage-merged/summary.json').statements || 'N/A'")
            LINES=$(node -p "require('./coverage-merged/summary.json').lines || 'N/A'")
            {
              echo "## Merged Coverage";
              echo "- Statements: ${STMT}%";
              echo "- Lines: ${LINES}%";
            } >> $GITHUB_STEP_SUMMARY
          else
            echo "No merged summary produced" >> $GITHUB_STEP_SUMMARY
          fi
      - name: Enforce merged coverage threshold
        if: always()
        run: |
          THRESHOLD=${COVERAGE_STMTS_THRESHOLD:-70}
          if [ -f coverage-merged/summary.json ]; then
            STMT=$(node -p "parseFloat(require('./coverage-merged/summary.json').statements || '0')")
            echo "Merged statements coverage=${STMT}%, threshold=${THRESHOLD}%"
            awk -v s="$STMT" -v t="$THRESHOLD" 'BEGIN { exit (s+0 >= t+0) ? 0 : 1 }'
          else
            echo 'No merged summary produced'; exit 1
          fi
      - name: Comment merged coverage on PR/Commit
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            let stmt='N/A', lines='N/A';
            try { const s = JSON.parse(fs.readFileSync('coverage-merged/summary.json','utf8')); stmt=s.statements; lines=s.lines; } catch {}
            const body = `## Merged Coverage\n\n- Statements: ${stmt}%\n- Lines: ${lines}%\n`;
            async function safeCall(fn, args){ try { return await fn(args); } catch (e){ core.warning(`Comment failed: ${e.message}`); } }
            if (context.payload.pull_request) {
              await safeCall(github.rest.issues.createComment, { owner: context.repo.owner, repo: context.repo.repo, issue_number: context.issue.number, body });
            } else if (context.eventName === 'push') {
              await safeCall(github.rest.repos.createCommitComment, { owner: context.repo.owner, repo: context.repo.repo, commit_sha: context.sha, body });
            } else {
              core.info('No PR or push context; skip commenting.');
            }
      - name: Summarize matrix results
        uses: actions/github-script@v7
        with:
          script: |
            async function tryListJobs() {
              try {
                const jobs = await github.rest.actions.listJobsForWorkflowRun({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  run_id: context.runId
                });
                return jobs.data.jobs;
              } catch (e) {
                core.warning(`listJobs failed: ${e.message}`);
                return [];
              }
            }
            const jobs = await tryListJobs();
            const rows = jobs.length
              ? jobs.filter(j => j.name && j.name.includes('test'))
                    .map(j => `| ${j.name.replace('test / ', '')} | ${j.conclusion || 'in_progress'} |`)
              : [`| unit | see checks |`, `| integration | see checks |`, `| cb-rate | see checks |`, `| event-metrics | see checks |`];
            const body = `## Matrix Test Results\n\n| Group | Status |\n|---|---|\n${rows.join('\n')}`;
            if (context.payload.pull_request) {
              try {
                await github.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: context.issue.number,
                  body
                });
              } catch (e) {
                core.warning(`PR comment failed: ${e.message}`);
                core.info(body);
              }
            } else {
              core.info(body);
            }